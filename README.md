# ğŸš€ Local RAG Pipeline

<div align="center">

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

**A production-ready RAG pipeline combining vector search and knowledge graphs for intelligent document interaction**

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Documentation](#-documentation) â€¢ [Examples](#-examples) â€¢ [Contributing](#-contributing)

</div>

---
![RAG pipeline](./img/RAG-pipeline.png)

## ğŸ¯ What is This?

A **fully local, privacy-focused** Retrieval-Augmented Generation (RAG) pipeline that lets you chat with your documents using AI. No external APIs, no data leaving your machine.

### Why This Exists

Most RAG solutions either:
- ğŸ“¡ Send your data to external APIs (privacy concerns)
- ğŸ” Use only vector search (missing relationships)
- ğŸ§© Are incomplete (no persistence, poor documentation)

**This pipeline solves all three:**
- ğŸ”’ **100% Local**: Everything runs on your machine
- ğŸ•¸ï¸ **Hybrid Search**: Vector similarity + Knowledge graph relationships
- ğŸ“¦ **Production Ready**: Complete with persistence, error handling, and extensive documentation

---

## âœ¨ Features

### Core Capabilities
- ğŸ” **Hybrid Search Engine**
  - FAISS vector similarity search
  - NetworkX knowledge graph relationships
  - Intelligent fusion of both approaches

- ğŸ“š **Multi-Format Support**
  - PDF, DOCX, TXT, Markdown, CSV
  - Automatic chunking and preprocessing
  - Metadata preservation

- ğŸ¤– **Local LLM Integration**
  - HuggingFace Transformers
  - Customizable models (phi-2, Mistral, Llama, etc.)
  - Streaming support ready

- ğŸ’¾ **Persistence Layer**
  - Save/load indices
  - Portable between machines
  - Incremental updates supported

### User Experience
- ğŸ’¬ **Interactive CLI** - Chat with your documents
- ğŸ **Python API** - Programmatic access
- ğŸ““ **Jupyter Notebook** - Interactive exploration
- âš™ï¸ **Easy Configuration** - Single config file

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/local-rag-pipeline.git
cd local-rag-pipeline

# Run automated setup
chmod +x setup.sh
./setup.sh
```

Or manually:

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Usage

**1. Prepare Your Documents**
```bash
mkdir my_documents
cp /path/to/your/documents/* my_documents/
```

**2. Initialize the Pipeline**
```bash
python src/rag_interface.py --documents ./my_documents
```

**3. Start Asking Questions!**
```
[HYBRID] ğŸ’¬ You: What are the main topics in my documents?

ğŸ” Searching...

ğŸ¤– Answer:
The main topics include machine learning fundamentals, neural network 
architectures, and practical applications of AI...

ğŸ“š Sources:
1. ml_guide.pdf
2. neural_networks.docx
```

---

## ğŸ“– Documentation

| Document | Description |
|----------|-------------|
| [Getting Started](docs/GETTING_STARTED.md) | Step-by-step setup guide |
| [User Guide](docs/USER_GUIDE.md) | Complete usage documentation |
| [Architecture](docs/ARCHITECTURE.md) | Technical architecture details |
| [API Reference](docs/API_REFERENCE.md) | Python API documentation |
| [Configuration](docs/CONFIGURATION.md) | Configuration options |
| [Troubleshooting](docs/TROUBLESHOOTING.md) | Common issues and solutions |

---

## ğŸ’¡ Examples

### Command Line Interface
```bash
# Interactive mode
python src/rag_interface.py

# Single query
python src/rag_interface.py --query "What is machine learning?"

# Custom models
python src/rag_interface.py \
    --embedding-model all-mpnet-base-v2 \
    --llm-model mistralai/Mistral-7B-Instruct-v0.1
```

### Python API
```python
from src.rag_pipeline import LocalRAGPipeline

# Initialize
rag = LocalRAGPipeline(
    embedding_model="all-MiniLM-L6-v2",
    llm_model="microsoft/phi-2"
)

# Load documents
documents = rag.load_documents("./my_documents")
rag.build_vector_index(documents)
rag.build_knowledge_graph(documents)

# Query
result = rag.query(
    "What are the key concepts?",
    search_type="hybrid",
    top_k=5
)

print(result['answer'])
```

### Jupyter Notebook
```bash
jupyter notebook examples/rag_notebook.ipynb
```

See [examples/](examples/) for more detailed examples.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Your Documents                        â”‚
â”‚              (PDF, DOCX, TXT, MD, CSV)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Document Loader & Chunker     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                      â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Vector Indexâ”‚        â”‚Knowledge Graphâ”‚
  â”‚   (FAISS)   â”‚        â”‚  (NetworkX)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Hybrid Search  â”‚
           â”‚   & Reranking  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Local LLM    â”‚
           â”‚Answer Generationâ”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technology Stack

| Component | Technology |
|-----------|-----------|
| **Embeddings** | Sentence-Transformers |
| **Vector Store** | FAISS |
| **Knowledge Graph** | NetworkX |
| **LLM** | HuggingFace Transformers |
| **Document Loaders** | LangChain Community |
| **Framework** | Python 3.8+ |

---

## âš™ï¸ Configuration

Edit `src/config.py` to customize:

```python
# Model Selection
EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # Fast, lightweight
LLM_MODEL = "microsoft/phi-2"          # Small but capable

# Search Configuration
DEFAULT_SEARCH_TYPE = "hybrid"  # vector, graph, or hybrid
VECTOR_WEIGHT = 0.7  # Weight for vector search
GRAPH_WEIGHT = 0.3   # Weight for graph search

# Performance
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50
USE_GPU = True
```

---

## ğŸ“Š Performance

### Default Configuration
- **Embedding Model**: all-MiniLM-L6-v2 (~80MB)
- **LLM**: microsoft/phi-2 (~5GB)
- **RAM Usage**: ~8GB
- **Query Speed**: 2-5 seconds (CPU), 0.5-1 second (GPU)

### Optimization Tips
- **Speed**: Use smaller models, GPU acceleration, larger chunks
- **Quality**: Use larger models, smaller chunks, increase top_k
- **Scale**: Use IVF FAISS index, implement batching

---

## ğŸ”’ Privacy & Security

âœ… **100% Local Processing** - No external API calls  
âœ… **No Data Collection** - Your documents stay on your machine  
âœ… **Open Source** - Fully auditable code  
âœ… **Offline Capable** - Works without internet (after model download)  
âœ… **Encrypted Storage** - Compatible with encrypted filesystems  

---

## ğŸ§ª Testing

```bash
# Run tests
python -m pytest tests/

# Run specific test
python -m pytest tests/test_pipeline.py

# With coverage
python -m pytest --cov=src tests/
```

---

## ğŸ—ºï¸ Roadmap

- [ ] Advanced entity extraction with spaCy NER
- [ ] Cross-encoder reranking
- [ ] Multi-modal support (images, tables)
- [ ] Web UI with Gradio
- [ ] RESTful API server
- [ ] Docker containerization
- [ ] Incremental indexing
- [ ] Multi-language support

See [ROADMAP.md](docs/ROADMAP.md) for details.

---

## ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Ways to Contribute
- ğŸ› Report bugs
- ğŸ’¡ Suggest features
- ğŸ“– Improve documentation
- ğŸ”§ Submit pull requests
- â­ Star the repository

---

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

Built with:
- [Sentence-Transformers](https://www.sbert.net/) for embeddings
- [FAISS](https://github.com/facebookresearch/faiss) for vector search
- [NetworkX](https://networkx.org/) for knowledge graphs
- [HuggingFace Transformers](https://huggingface.co/transformers/) for LLMs
- [LangChain](https://github.com/langchain-ai/langchain) for document loaders

---

## ğŸ“ Support

- ğŸ“– [Documentation](docs/)
- ğŸ’¬ [Discussions](https://github.com/yourusername/local-rag-pipeline/discussions)
- ğŸ› [Issue Tracker](https://github.com/yourusername/local-rag-pipeline/issues)

---

## ğŸŒŸ Star History

If you find this project useful, please consider giving it a star! â­

---

<div align="center">

**Built with â¤ï¸ for privacy-conscious developers**

[â¬† back to top](#-local-rag-pipeline)

</div>
